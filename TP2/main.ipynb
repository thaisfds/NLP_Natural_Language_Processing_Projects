{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertForTokenClassification, get_scheduler, Trainer, TrainingArguments, AdamW\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenização com BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações iniciais\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Caminhos para os arquivos de dados\n",
    "train_file = \"./corpus/macmorpho-train.txt\"\n",
    "val_file = \"./corpus/macmorpho-dev.txt\"\n",
    "test_file = \"./corpus/macmorpho-test.txt\"\n",
    "\n",
    "data_files = {\n",
    "    \"train\": train_file,\n",
    "    \"validation\": val_file,\n",
    "    \"test\": test_file,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar os dados\n",
    "def load_data(filepath):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            tokens, tags = [], []\n",
    "            for pair in line.strip().split():\n",
    "                word, tag = pair.rsplit(\"_\", 1)\n",
    "                tokens.append(word)\n",
    "                tags.append(tag)\n",
    "            sentences.append(tokens)\n",
    "            labels.append(tags)\n",
    "    return sentences, labels\n",
    "\n",
    "# Carregar os dados\n",
    "tokens_train, tags_train = load_data(train_file)\n",
    "tokens_val, tags_val = load_data(val_file)\n",
    "tokens_test, tags_test = load_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o tokenizer e o modelo pré-treinado\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "num_classes = len(set(tag for sent_tags in tags_train for tag in sent_tags))\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"neuralmind/bert-base-portuguese-cased\",\n",
    "    num_labels=num_classes\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder para as tags\n",
    "tag_encoder = LabelEncoder()\n",
    "tag_encoder.fit([tag for sent_tags in tags_train for tag in sent_tags])\n",
    "\n",
    "def preprocess(sentences, tags, tokenizer, tag_encoder):\n",
    "    input_ids, attention_masks, labels = [], [], []\n",
    "\n",
    "    for sentence, tag_seq in zip(sentences, tags):\n",
    "        # Tokenizar as frases\n",
    "        encoding = tokenizer(\n",
    "            sentence,\n",
    "            is_split_into_words=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Ajustar os rótulos para sub-tokens\n",
    "        word_ids = encoding.word_ids()\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)  # Ignorar sub-tokens fora da sequência\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(tag_encoder.transform([tag_seq[word_idx]])[0])\n",
    "            else:\n",
    "                label_ids.append(-100)  # Ignorar sub-tokens adicionais\n",
    "\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        input_ids.append(encoding[\"input_ids\"])\n",
    "        attention_masks.append(encoding[\"attention_mask\"])\n",
    "        labels.append(torch.tensor(label_ids))\n",
    "\n",
    "    return torch.cat(input_ids), torch.cat(attention_masks), torch.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processar os dados\n",
    "train_inputs, train_masks, train_labels = preprocess(tokens_train, tags_train, tokenizer, tag_encoder)\n",
    "val_inputs, val_masks, val_labels = preprocess(tokens_val, tags_val, tokenizer, tag_encoder)\n",
    "\n",
    "def create_dataloader(inputs, masks, labels, batch_size=16):\n",
    "    data = TensorDataset(inputs, masks, labels)\n",
    "    return DataLoader(data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar os DataLoaders\n",
    "train_dataloader = create_dataloader(train_inputs, train_masks, train_labels) #usar para treinar\n",
    "test_dataloader = create_dataloader(val_inputs, val_masks, val_labels) #usar para testar\n",
    "val_dataloader = create_dataloader(val_inputs, val_masks, val_labels) #usar para validar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred, unique_labels):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), axis=-1)\n",
    "    predictions = predictions.flatten().cpu().numpy()\n",
    "    labels = labels.flatten().cpu().numpy()\n",
    "\n",
    "    # Filtrando os valores -100, que são usados para ignorar tokens\n",
    "    mask = labels != -100\n",
    "    predictions = predictions[mask]\n",
    "    labels = labels[mask]\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    # Adicione outras métricas conforme necessário, como F1-score\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo de treinamento: {'text': 'Jersei_N atinge_V média_N de_PREP Cr$_CUR 1,4_NUM milhão_N na_PREP+ART venda_N da_PREP+ART Pinhal_NPROP em_PREP São_NPROP Paulo_NPROP ._PU'}\n",
      "Exemplo de validação: {'text': 'Ainda_ADV em_PREP dezembro_N de_PREP 1990_N ,_PU foi_V editada_PCP a_ART famosa_ADJ 289_N ,_PU que_PRO-KS modificava_V a_ART sistemática_N da_PREP+ART arrecadação_N do_PREP+ART ITR_NPROP e_KC alterava_V suas_PROADJ alíquotas_N ._PU'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156/156 18:50, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=156, training_loss=0.4090093519443121, metrics={'train_runtime': 1137.9152, 'train_samples_per_second': 8.788, 'train_steps_per_second': 0.137, 'total_flos': 652338220105728.0, 'train_loss': 0.4090093519443121, 'epoch': 0.9968051118210862})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"./training_output\"\n",
    "# Definir o otimizador\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "unique_labels = tag_encoder.classes_\n",
    "\n",
    "# Supondo que os arquivos estejam no formato linha por linha (ajuste o formato, se necessário)\n",
    "datasets = load_dataset(\"text\", data_files=data_files)\n",
    "\n",
    "# Divisão dos datasets\n",
    "train_dataset = datasets[\"train\"]\n",
    "test_dataset = datasets[\"test\"]\n",
    "val_dataset = datasets[\"validation\"]\n",
    "\n",
    "# Verificação das amostras (opcional)\n",
    "print(f\"Exemplo de treinamento: {train_dataset[0]}\")\n",
    "print(f\"Exemplo de teste: {test_dataset[0]}\")\n",
    "print(f\"Exemplo de validação: {val_dataset[0]}\")\n",
    "\n",
    "def create_hf_dataset(inputs, masks, labels):\n",
    "    data = {\n",
    "        \"input_ids\": inputs.tolist(),\n",
    "        \"attention_mask\": masks.tolist(),\n",
    "        \"labels\": labels.tolist(),\n",
    "    }\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "# Criar datasets no formato esperado\n",
    "train_dataset = create_hf_dataset(train_inputs, train_masks, train_labels)\n",
    "train_dataset = train_dataset.select(range(10000))  # Usar apenas 10.000 exemplos\n",
    "\n",
    "test_dataset = create_hf_dataset(val_inputs, val_masks, val_labels)\n",
    "val_dataset = create_hf_dataset(val_inputs, val_masks, val_labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    load_best_model_at_end=True,\n",
    "    output_dir=PATH,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=300,\n",
    "    save_steps=300,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    logging_dir=f\"{PATH}/log\",\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Limpar cache da GPU\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Criar o Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,   # Dataset de treinamento no formato esperado\n",
    "    eval_dataset=test_dataset,     # Dataset de test no formato esperado\n",
    "    optimizers=(optimizer, None),  # Passando o otimizador\n",
    "    compute_metrics=lambda eval_pred: compute_metrics(eval_pred, unique_labels),\n",
    ")\n",
    "\n",
    "# Iniciar o treinamento\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para salvar o modelo\n",
    "def save_model(model, tokenizer, save_directory):\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    model.save_pretrained(save_directory)\n",
    "    tokenizer.save_pretrained(save_directory)\n",
    "    print(f\"Modelo salvo em: {save_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em: ./saved_model\n"
     ]
    }
   ],
   "source": [
    "# Salvar o modelo após o treinamento\n",
    "save_directory = \"./saved_model\"\n",
    "save_model(model, tokenizer, save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores previstos e esperados (apenas para os primeiros exemplos):\n",
      "Frase em análise: Ainda em dezembro de 1990 , foi editada a famosa 28 , que mod a sistemática da arrecadação do I e alter suas al .\n",
      "Previsto: ['ADV' 'PREP' 'N' 'PREP' 'N' 'PU' 'V' 'PCP' 'ART' 'ADJ' 'N' 'PU' 'PRO-KS'\n",
      " 'V' 'ART' 'N' 'PREP+ART' 'N' 'PREP+ART' 'NPROP' 'KC' 'V' 'PROADJ' 'N'\n",
      " 'PU']\n",
      "Esperado: ['ADV' 'PREP' 'N' 'PREP' 'N' 'PU' 'V' 'PCP' 'ART' 'ADJ' 'N' 'PU' 'PRO-KS'\n",
      " 'V' 'ART' 'N' 'PREP+ART' 'N' 'PREP+ART' 'NPROP' 'KC' 'V' 'PROADJ' 'N'\n",
      " 'PU']\n",
      "--------------------------------------------------\n",
      "Frase em análise: Porém , como a previsão indica entrada de frente fria , deve - aguarda até quarta e irrig somente se o total de chuva for inferior a 30 mm .\n",
      "Previsto: ['KC' 'PU' 'KS' 'ART' 'N' 'V' 'N' 'PREP' 'N' 'ADJ' 'PU' 'V' 'PROPESS' 'V'\n",
      " 'PREP' 'N' 'KC' 'V' 'PDEN' 'KS' 'ART' 'N' 'PREP' 'N' 'V' 'ADJ' 'PREP'\n",
      " 'NUM' 'N' 'PU']\n",
      "Esperado: ['KC' 'PU' 'KS' 'ART' 'N' 'V' 'N' 'PREP' 'N' 'ADJ' 'PU' 'V' 'PROPESS' 'V'\n",
      " 'PREP' 'N' 'KC' 'V' 'PDEN' 'KS' 'ART' 'N' 'PREP' 'N' 'V' 'ADJ' 'PREP'\n",
      " 'NUM' 'N' 'PU']\n",
      "--------------------------------------------------\n",
      "Frase em análise: \" O crescimento é express mas , mesmo assim , estamos abaixo da média histórica do setor , que é de 45 mil tra por ano \" , diz Pas .\n",
      "Previsto: ['PU' 'ART' 'N' 'V' 'ADJ' 'KC' 'PU' 'PDEN' 'ADV' 'PU' 'V' 'PREP'\n",
      " 'PREP+ART' 'N' 'ADJ' 'PREP+ART' 'N' 'PU' 'PRO-KS' 'V' 'PREP' 'NUM' 'NUM'\n",
      " 'N' 'PREP' 'N' 'PU' 'PU' 'V' 'NPROP' 'PU']\n",
      "Esperado: ['PU' 'ART' 'N' 'V' 'ADJ' 'KC' 'PU' 'PDEN' 'PDEN' 'PU' 'V' 'PREP'\n",
      " 'PREP+ART' 'N' 'ADJ' 'PREP+ART' 'N' 'PU' 'PRO-KS' 'V' 'PREP' 'NUM' 'NUM'\n",
      " 'N' 'PREP' 'N' 'PU' 'PU' 'V' 'NPROP' 'PU']\n",
      "--------------------------------------------------\n",
      "Frase em análise: O programa atende ainda as culturas de feijão ( primeira e segunda sa ) , arroz de vá e mam , cujas estimativas de produção ainda não foram elaborada .\n",
      "Previsto: ['ART' 'N' 'V' 'ADV' 'ART' 'N' 'PREP' 'N' 'PU' 'ADJ' 'KC' 'ADJ' 'N' 'PU'\n",
      " 'PU' 'N' 'PREP' 'N' 'KC' 'N' 'PU' 'PRO-KS' 'N' 'PREP' 'N' 'ADV' 'ADV' 'V'\n",
      " 'PCP' 'PU']\n",
      "Esperado: ['ART' 'N' 'V' 'ADV' 'ART' 'N' 'PREP' 'N' 'PU' 'ADJ' 'KC' 'ADJ' 'N' 'PU'\n",
      " 'PU' 'N' 'PREP' 'N' 'KC' 'N' 'PU' 'PRO-KS' 'N' 'PREP' 'N' 'ADV' 'ADV' 'V'\n",
      " 'PCP' 'PU']\n",
      "--------------------------------------------------\n",
      "Frase em análise: de qualquer maneira , toda essa \" informal \" na produção de sementes não foi obs a um enorme crescimento deste segmento da agricultura .\n",
      "Previsto: ['PREP' 'PROADJ' 'N' 'PU' 'PROADJ' 'PROADJ' 'PU' 'N' 'PU' 'PREP+ART' 'N'\n",
      " 'PREP' 'N' 'ADV' 'V' 'N' 'PREP' 'ART' 'ADJ' 'N' 'PREP+PROADJ' 'N'\n",
      " 'PREP+ART' 'N' 'PU']\n",
      "Esperado: ['PREP' 'PROADJ' 'N' 'PU' 'PROADJ' 'PROADJ' 'PU' 'N' 'PU' 'PREP+ART' 'N'\n",
      " 'PREP' 'N' 'ADV' 'V' 'N' 'PREP' 'ART' 'ADJ' 'N' 'PREP+PROADJ' 'N'\n",
      " 'PREP+ART' 'N' 'PU']\n",
      "--------------------------------------------------\n",
      "Frase em análise: É divulgar procedimentos adequados de mane do solo , dar assistência técnica eficaz ao produtor e impla programas de educação ambiental nas escolas .\n",
      "Previsto: ['V' 'V' 'N' 'ADJ' 'PREP' 'N' 'PREP+ART' 'N' 'PU' 'V' 'N' 'ADJ' 'ADJ'\n",
      " 'PREP+ART' 'N' 'KC' 'V' 'N' 'PREP' 'N' 'ADJ' 'PREP+ART' 'N' 'PU']\n",
      "Esperado: ['V' 'V' 'N' 'PCP' 'PREP' 'N' 'PREP+ART' 'N' 'PU' 'V' 'N' 'ADJ' 'ADJ'\n",
      " 'PREP+ART' 'N' 'KC' 'V' 'N' 'PREP' 'N' 'ADJ' 'PREP+ART' 'N' 'PU']\n",
      "--------------------------------------------------\n",
      "Frase em análise: Os países ricos não concorda .\n",
      "Previsto: ['ART' 'N' 'ADJ' 'ADV' 'V' 'PU']\n",
      "Esperado: ['ART' 'N' 'ADJ' 'ADV' 'V' 'PU']\n",
      "--------------------------------------------------\n",
      "Frase em análise: Ev , dessa forma , que plantio inadequ ao tipo de solo acel o processo de erosão .\n",
      "Previsto: ['V' 'PU' 'PREP+PROADJ' 'N' 'PU' 'KS' 'N' 'ADJ' 'PREP+ART' 'N' 'PREP' 'N'\n",
      " 'V' 'ART' 'N' 'PREP' 'N' 'PU']\n",
      "Esperado: ['V' 'PU' 'PREP+PROADJ' 'N' 'PU' 'KS' 'N' 'ADJ' 'PREP+ART' 'N' 'PREP' 'N'\n",
      " 'V' 'ART' 'N' 'PREP' 'N' 'PU']\n",
      "--------------------------------------------------\n",
      "Frase em análise: Um exemplo é a bacia do Vale do Piracicaba ( a 170 quilômetros a noroeste de São Paulo ) .\n",
      "Previsto: ['ART' 'N' 'V' 'ART' 'N' 'PREP+ART' 'NPROP' 'NPROP' 'NPROP' 'PU' 'PREP'\n",
      " 'NUM' 'N' 'PREP' 'N' 'PREP' 'NPROP' 'NPROP' 'PU' 'PU']\n",
      "Esperado: ['ART' 'N' 'V' 'ART' 'N' 'PREP+ART' 'NPROP' 'NPROP' 'NPROP' 'PU' 'PREP'\n",
      " 'NUM' 'N' 'PREP' 'N' 'PREP' 'NPROP' 'NPROP' 'PU' 'PU']\n",
      "--------------------------------------------------\n",
      "Frase em análise: A terra , que esco junto , chega ao rio e diminui o seu leito ( asso ) .\n",
      "Previsto: ['ART' 'N' 'PU' 'PRO-KS' 'V' 'ADV' 'PU' 'V' 'PREP+ART' 'N' 'KC' 'V' 'ART'\n",
      " 'PROADJ' 'N' 'PU' 'N' 'PU' 'PU']\n",
      "Esperado: ['ART' 'N' 'PU' 'PRO-KS' 'V' 'ADV' 'PU' 'V' 'PREP+ART' 'N' 'KC' 'V' 'ART'\n",
      " 'PROADJ' 'N' 'PU' 'N' 'PU' 'PU']\n",
      "--------------------------------------------------\n",
      "Acurácia no conjunto de teste: 0.9692\n"
     ]
    }
   ],
   "source": [
    "# Avaliação no conjunto de teste\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Para imprimir valores previstos e esperados\n",
    "print(\"Valores previstos e esperados (apenas para os primeiros exemplos):\")\n",
    "\n",
    "# Contador para limitar o número de exemplos impressos\n",
    "print_count = 0\n",
    "max_print = 10  # Defina o número de exemplos que você deseja imprimir\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:  # Você pode trocar por test_dataloader, se necessário\n",
    "        batch_input_ids, batch_masks, batch_labels = [b.to(device) for b in batch]\n",
    "        \n",
    "        outputs = model(input_ids=batch_input_ids, attention_mask=batch_masks)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        labels = batch_labels.cpu().numpy()\n",
    "\n",
    "        # Ignorar tokens -100\n",
    "        for pred, label, input_ids in zip(predictions, labels, batch_input_ids):\n",
    "            mask = label != -100\n",
    "            pred = pred[mask]\n",
    "            label = label[mask]\n",
    "            input_ids = input_ids[mask].cpu().numpy()  # Selecionando apenas os ids de tokens relevantes\n",
    "\n",
    "            all_predictions.extend(pred)\n",
    "            all_labels.extend(label)\n",
    "\n",
    "            # Limitar a impressão dos primeiros 10 exemplos\n",
    "            if print_count < max_print:\n",
    "                pred_tags = tag_encoder.inverse_transform(pred)  # Convertendo para as tags originais\n",
    "                label_tags = tag_encoder.inverse_transform(label)  # Convertendo para as tags originais\n",
    "                sentence = tokenizer.convert_ids_to_tokens(input_ids)  # Usando os input_ids para recuperar a frase original\n",
    "\n",
    "                print(f\"Frase em análise: {' '.join(sentence)}\")\n",
    "                print(f\"Previsto: {pred_tags}\")\n",
    "                print(f\"Esperado: {label_tags}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "                print_count += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "# Calcular acurácia\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
