{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento de Linguagem Natural - Trabalho Prático 1\n",
    "### Thaís Ferreira da Silva - 2021092571"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports do gensim - para word2vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "# Imports essenciais\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessamento do dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english', 'revolution', 'and', 'the', 'sans', 'culottes', 'of', 'the', 'french', 'revolution', 'whilst', 'the', 'term', 'is', 'still', 'used', 'in', 'a', 'pejorative', 'way', 'to', 'describe', 'any', 'act', 'that', 'used', 'violent', 'means', 'to', 'destroy', 'the']\n"
     ]
    }
   ],
   "source": [
    "text8_path = './text8'\n",
    "questions_words_path = os.path.abspath('./mini-questions-words.txt')\n",
    "corpus = Text8Corpus(text8_path)\n",
    "\n",
    "# Visualizando as primeiras palavras do corpus\n",
    "sentence = next(iter(corpus))\n",
    "print(sentence[:50])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_analogies(file_path):\n",
    "    \"\"\"Carrega as analogias do arquivo questions-words.txt.\"\"\"\n",
    "    analogies = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith(':'):  # Ignorar categorias\n",
    "                continue\n",
    "            words = line.split()\n",
    "            if len(words) == 4:\n",
    "                analogies.append(tuple(words))  # ('Athens', 'Greece', 'Baghdad', 'Iraq')\n",
    "    return analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hyperparameter_combinations(param_grid):\n",
    "    \"\"\"Gera todas as combinações de hiperparâmetros\"\"\"\n",
    "    from itertools import product\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "    return combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(corpus, params, output_dir):\n",
    "    model_name = f\"word2vec_vs{params['vector_size']}_win{params['window']}_sg{params['sg']}_ep{params['epochs']}\"\n",
    "    print(f\"Treinando modelo: {model_name}\")\n",
    "    \n",
    "    model = Word2Vec(\n",
    "        sentences=corpus,\n",
    "        vector_size=params['vector_size'],\n",
    "        window=params['window'],\n",
    "        sg=params['sg'],\n",
    "        epochs=params['epochs'],\n",
    "        workers=4\n",
    "    )\n",
    "    \n",
    "    model_path = os.path.join(output_dir, f\"{model_name}.model\")\n",
    "    model.save(model_path)\n",
    "    print(f\"Modelo salvo: {model_path}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_analogies(model, analogies):\n",
    "    \"\"\"Realiza operações de analogia e verifica as palavras mais próximas\"\"\"\n",
    "    results = []\n",
    "    for analogy in analogies:\n",
    "        try:\n",
    "            # Verificando se todas as palavras estão no vocabulário do modelo\n",
    "            missing_words = [word for word in analogy if word not in model.wv]\n",
    "            if missing_words:\n",
    "                results.append((analogy, None, None, False, f\"Palavras ausentes: {', '.join(missing_words)}\"))\n",
    "                continue\n",
    "\n",
    "            positive = [analogy[1], analogy[0]]  # France + Paris\n",
    "            negative = [analogy[2]]  # Berlin\n",
    "            result = model.wv.most_similar(positive=positive, negative=negative, topn=1)\n",
    "            predicted_word = result[0][0]\n",
    "            expected_word = analogy[3]  #Germany\n",
    "            correct = predicted_word == expected_word\n",
    "            results.append((analogy, predicted_word, expected_word, correct))\n",
    "        \n",
    "        except KeyError as e:\n",
    "            results.append((analogy, None, None, False, f\"Erro: {e}\"))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de analogias carregadas: 22\n"
     ]
    }
   ],
   "source": [
    "analogies = load_analogies(questions_words_path)\n",
    "print(f\"Total de analogias carregadas: {len(analogies)}\")\n",
    "\n",
    "\n",
    "output_dir = './word2vec_models'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Hiperparâmetros para o GridSearch\n",
    "param_grid = {\n",
    "    'vector_size': [50, 100, 200],      # Tamanho do vetor de palavras\n",
    "    'window': [3, 5, 7],                # Tamanho da janela de contexto\n",
    "    'sg': [0, 1],                      # CBOW (0) ou Skip-gram (1)\n",
    "    'epochs': [5, 10, 15],             # Número de iterações de treinamento\n",
    "}\n",
    "\n",
    "# Gerar combinações de hiperparâmetros\n",
    "combinations = generate_hyperparameter_combinations(param_grid)\n",
    "results_summary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário do modelo: ['the', 'of', 'and', 'one', 'in', 'a', 'to', 'zero', 'nine', 'two']\n",
      "Athena está no vocabulário? False\n",
      "Greece está no vocabulário? False\n",
      "Total de analogias: 22\n",
      "Corretas: 0\n",
      "Acurácia: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# for i, params in enumerate(combinations):\n",
    "#     print(f\"\\nTreinando combinação {i+1}/{len(combinations)}: {params}\\n\")\n",
    "#     model = train_and_save_model(corpus, params, output_dir)\n",
    "    \n",
    "#     # Avaliar o modelo usando as operações de analogia\n",
    "#     analogy_results = evaluate_analogies(model, analogies)\n",
    "    \n",
    "#     # Exibir os resultados de cada analogia\n",
    "#     for analogy, predicted, expected, correct in analogy_results[:5]:  # Mostra as 5 primeiras\n",
    "#         print(f\"Analogia: {analogy} | Previsto: {predicted} | Esperado: {expected} | Correto: {correct}\")\n",
    "    \n",
    "#     # Salvar o desempenho geral dessa configuração\n",
    "#     accuracy = sum(1 for _, _, _, correct in analogy_results if correct) / len(analogy_results)\n",
    "#     results_summary.append((params, accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análise de analogia (minúsculas): ['athens', 'greece', 'baghdad', 'iraq']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'bangkok', 'thailand']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'beijing', 'china']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'berlin', 'germany']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'bern', 'switzerland']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'cairo', 'egypt']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'canberra', 'australia']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'hanoi', 'vietnam']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'havana', 'cuba']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'helsinki', 'finland']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'islamabad', 'pakistan']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'kabul', 'afghanistan']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'london', 'england']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'madrid', 'spain']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'moscow', 'russia']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'oslo', 'norway']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'ottawa', 'canada']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'paris', 'france']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'rome', 'italy']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'stockholm', 'sweden']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'tehran', 'iran']\n",
      "Análise de analogia (minúsculas): ['athens', 'greece', 'tokyo', 'japan']\n",
      "Total de analogias: 22\n",
      "Corretas: 0\n",
      "Acurácia: 0.00%\n",
      "\n",
      "Primeiros 10 resultados:\n",
      "Analogia: ('Athens', 'Greece', 'Baghdad', 'Iraq') | Previsto: macedonia | Esperado: iraq | Correto: False\n",
      "Analogia: ('Athens', 'Greece', 'Bangkok', 'Thailand') | Previsto: athenian | Esperado: thailand | Correto: False\n",
      "Analogia: ('Athens', 'Greece', 'Beijing', 'China') | Previsto: thessaly | Esperado: china | Correto: False\n",
      "Analogia: ('Athens', 'Greece', 'Berlin', 'Germany') | Previsto: crete | Esperado: germany | Correto: False\n",
      "Analogia: ('Athens', 'Greece', 'Bern', 'Switzerland') | Previsto: athenian | Esperado: switzerland | Correto: False\n",
      "Analogia: ('Athens', 'Greece', 'Cairo', 'Egypt') | Previsto: aegina | Esperado: egypt | Correto: False\n",
      "Analogia: ('Athens', 'Greece', 'Canberra', 'Australia') | Previsto: megara | Esperado: australia | Correto: False\n",
      "Analogia: ('Athens', 'Greece', 'Hanoi', 'Vietnam') | Previsto: crete | Esperado: vietnam | Correto: False\n",
      "Analogia: ('Athens', 'Greece', 'Havana', 'Cuba') | Previsto: greek | Esperado: cuba | Correto: False\n",
      "Analogia: ('Athens', 'Greece', 'Helsinki', 'Finland') | Previsto: thessaly | Esperado: finland | Correto: False\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load('./word2vec_models/word2vec_vs200_win7_sg1_ep15.model')\n",
    "\n",
    "questions_words_path = './mini-questions-words.txt'\n",
    "analogies = load_analogies(questions_words_path)\n",
    "\n",
    "results = evaluate_analogies(model, analogies)\n",
    "\n",
    "correct = sum(1 for _, _, _, c, *rest in results if c)\n",
    "total = len(results)\n",
    "accuracy = correct / total if total > 0 else 0\n",
    "\n",
    "print(f\"Total de analogias: {total}\")\n",
    "print(f\"Corretas: {correct}\")\n",
    "print(f\"Acurácia: {accuracy:.2%}\")\n",
    "\n",
    "print(\"\\nPrimeiros 10 resultados:\")\n",
    "for analogy, predicted, expected, correct, *info in results[:10]:\n",
    "    print(f\"Analogia: {analogy} | Previsto: {predicted} | Esperado: {expected} | Correto: {correct}\")\n",
    "    if info:\n",
    "        print(f\"  Info extra: {info[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
